{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from json import loads, dumps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>raw_words</th>\n",
       "      <th>words</th>\n",
       "      <th>aspects</th>\n",
       "      <th>holder</th>\n",
       "      <th>opinions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DeVry_University_94_07-02-2004-1</td>\n",
       "      <td>NA Don't listen to above post .</td>\n",
       "      <td>[NA, Don't, listen, to, above, post, .]</td>\n",
       "      <td>[{'index': 0, 'from': 0, 'to': 1, 'term': 'NA'...</td>\n",
       "      <td>[{'index': 0, 'from': 0, 'to': 1, 'term': 'NA'}]</td>\n",
       "      <td>[{'index': 0, 'from': 0, 'to': 1, 'term': 'NA'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DeVry_University_94_07-02-2004-2</td>\n",
       "      <td>NA This school is all about the money</td>\n",
       "      <td>[NA, This, school, is, all, about, the, money]</td>\n",
       "      <td>[{'index': 0, 'from': 2, 'to': 3, 'term': 'sch...</td>\n",
       "      <td>[{'index': 0, 'from': 0, 'to': 1, 'term': 'NA'}]</td>\n",
       "      <td>[{'index': 0, 'from': 4, 'to': 5, 'term': 'all'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DeVry_University_94_07-02-2004-3</td>\n",
       "      <td>NA The education is less than stellar for the ...</td>\n",
       "      <td>[NA, The, education, is, less, than, stellar, ...</td>\n",
       "      <td>[{'index': 0, 'from': 2, 'to': 3, 'term': 'edu...</td>\n",
       "      <td>[{'index': 0, 'from': 0, 'to': 1, 'term': 'NA'}]</td>\n",
       "      <td>[{'index': 0, 'from': 4, 'to': 6, 'term': 'les...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DeVry_University_94_07-02-2004-4</td>\n",
       "      <td>NA A community college offers better than this...</td>\n",
       "      <td>[NA, A, community, college, offers, better, th...</td>\n",
       "      <td>[{'index': 0, 'from': 0, 'to': 1, 'term': 'NA'...</td>\n",
       "      <td>[{'index': 0, 'from': 0, 'to': 1, 'term': 'NA'}]</td>\n",
       "      <td>[{'index': 0, 'from': 0, 'to': 1, 'term': 'NA'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DeVry_University_94_07-02-2004-5</td>\n",
       "      <td>NA Here you pay 6k a semester as compared to 3...</td>\n",
       "      <td>[NA, Here, you, pay, 6k, a, semester, as, comp...</td>\n",
       "      <td>[{'index': 0, 'from': 0, 'to': 1, 'term': 'NA'...</td>\n",
       "      <td>[{'index': 0, 'from': 0, 'to': 1, 'term': 'NA'}]</td>\n",
       "      <td>[{'index': 0, 'from': 0, 'to': 1, 'term': 'NA'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4347</th>\n",
       "      <td>opener_en/kaf/hotel/english00011_0b57ac0ca8569...</td>\n",
       "      <td>NA Golf courses can be easily reached from the...</td>\n",
       "      <td>[NA, Golf, courses, can, be, easily, reached, ...</td>\n",
       "      <td>[{'index': 0, 'from': 11, 'to': 13, 'term': 't...</td>\n",
       "      <td>[{'index': 0, 'from': 0, 'to': 1, 'term': 'NA'...</td>\n",
       "      <td>[{'index': 0, 'from': 17, 'to': 18, 'term': 'o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4348</th>\n",
       "      <td>opener_en/kaf/hotel/english00011_0b57ac0ca8569...</td>\n",
       "      <td>NA Hotel offers nice spa , large pool area and...</td>\n",
       "      <td>[NA, Hotel, offers, nice, spa, ,, large, pool,...</td>\n",
       "      <td>[{'index': 0, 'from': 1, 'to': 2, 'term': 'Hot...</td>\n",
       "      <td>[{'index': 0, 'from': 0, 'to': 1, 'term': 'NA'...</td>\n",
       "      <td>[{'index': 0, 'from': 2, 'to': 3, 'term': 'off...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4349</th>\n",
       "      <td>opener_en/kaf/hotel/english00011_0b57ac0ca8569...</td>\n",
       "      <td>NA Hospitality and services at the highest lev...</td>\n",
       "      <td>[NA, Hospitality, and, services, at, the, high...</td>\n",
       "      <td>[{'index': 0, 'from': 1, 'to': 2, 'term': 'Hos...</td>\n",
       "      <td>[{'index': 0, 'from': 0, 'to': 1, 'term': 'NA'...</td>\n",
       "      <td>[{'index': 0, 'from': 4, 'to': 8, 'term': 'at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4350</th>\n",
       "      <td>opener_en/kaf/hotel/english00011_0b57ac0ca8569...</td>\n",
       "      <td>NA I will definitely come back !</td>\n",
       "      <td>[NA, I, will, definitely, come, back, !]</td>\n",
       "      <td>[{'index': 0, 'from': 0, 'to': 1, 'term': 'NA'...</td>\n",
       "      <td>[{'index': 0, 'from': 1, 'to': 2, 'term': 'I'}]</td>\n",
       "      <td>[{'index': 0, 'from': 2, 'to': 7, 'term': 'wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4351</th>\n",
       "      <td>opener_en/kaf/hotel/english00032_30ddf6dff464d...</td>\n",
       "      <td>NA Best in class</td>\n",
       "      <td>[NA, Best, in, class]</td>\n",
       "      <td>[{'index': 0, 'from': 0, 'to': 1, 'term': 'NA'...</td>\n",
       "      <td>[{'index': 0, 'from': 0, 'to': 1, 'term': 'NA'}]</td>\n",
       "      <td>[{'index': 0, 'from': 1, 'to': 2, 'term': 'Bes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4352 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sent_id  \\\n",
       "0                      DeVry_University_94_07-02-2004-1   \n",
       "1                      DeVry_University_94_07-02-2004-2   \n",
       "2                      DeVry_University_94_07-02-2004-3   \n",
       "3                      DeVry_University_94_07-02-2004-4   \n",
       "4                      DeVry_University_94_07-02-2004-5   \n",
       "...                                                 ...   \n",
       "4347  opener_en/kaf/hotel/english00011_0b57ac0ca8569...   \n",
       "4348  opener_en/kaf/hotel/english00011_0b57ac0ca8569...   \n",
       "4349  opener_en/kaf/hotel/english00011_0b57ac0ca8569...   \n",
       "4350  opener_en/kaf/hotel/english00011_0b57ac0ca8569...   \n",
       "4351  opener_en/kaf/hotel/english00032_30ddf6dff464d...   \n",
       "\n",
       "                                              raw_words  \\\n",
       "0                       NA Don't listen to above post .   \n",
       "1                 NA This school is all about the money   \n",
       "2     NA The education is less than stellar for the ...   \n",
       "3     NA A community college offers better than this...   \n",
       "4     NA Here you pay 6k a semester as compared to 3...   \n",
       "...                                                 ...   \n",
       "4347  NA Golf courses can be easily reached from the...   \n",
       "4348  NA Hotel offers nice spa , large pool area and...   \n",
       "4349  NA Hospitality and services at the highest lev...   \n",
       "4350                   NA I will definitely come back !   \n",
       "4351                                   NA Best in class   \n",
       "\n",
       "                                                  words  \\\n",
       "0               [NA, Don't, listen, to, above, post, .]   \n",
       "1        [NA, This, school, is, all, about, the, money]   \n",
       "2     [NA, The, education, is, less, than, stellar, ...   \n",
       "3     [NA, A, community, college, offers, better, th...   \n",
       "4     [NA, Here, you, pay, 6k, a, semester, as, comp...   \n",
       "...                                                 ...   \n",
       "4347  [NA, Golf, courses, can, be, easily, reached, ...   \n",
       "4348  [NA, Hotel, offers, nice, spa, ,, large, pool,...   \n",
       "4349  [NA, Hospitality, and, services, at, the, high...   \n",
       "4350           [NA, I, will, definitely, come, back, !]   \n",
       "4351                              [NA, Best, in, class]   \n",
       "\n",
       "                                                aspects  \\\n",
       "0     [{'index': 0, 'from': 0, 'to': 1, 'term': 'NA'...   \n",
       "1     [{'index': 0, 'from': 2, 'to': 3, 'term': 'sch...   \n",
       "2     [{'index': 0, 'from': 2, 'to': 3, 'term': 'edu...   \n",
       "3     [{'index': 0, 'from': 0, 'to': 1, 'term': 'NA'...   \n",
       "4     [{'index': 0, 'from': 0, 'to': 1, 'term': 'NA'...   \n",
       "...                                                 ...   \n",
       "4347  [{'index': 0, 'from': 11, 'to': 13, 'term': 't...   \n",
       "4348  [{'index': 0, 'from': 1, 'to': 2, 'term': 'Hot...   \n",
       "4349  [{'index': 0, 'from': 1, 'to': 2, 'term': 'Hos...   \n",
       "4350  [{'index': 0, 'from': 0, 'to': 1, 'term': 'NA'...   \n",
       "4351  [{'index': 0, 'from': 0, 'to': 1, 'term': 'NA'...   \n",
       "\n",
       "                                                 holder  \\\n",
       "0      [{'index': 0, 'from': 0, 'to': 1, 'term': 'NA'}]   \n",
       "1      [{'index': 0, 'from': 0, 'to': 1, 'term': 'NA'}]   \n",
       "2      [{'index': 0, 'from': 0, 'to': 1, 'term': 'NA'}]   \n",
       "3      [{'index': 0, 'from': 0, 'to': 1, 'term': 'NA'}]   \n",
       "4      [{'index': 0, 'from': 0, 'to': 1, 'term': 'NA'}]   \n",
       "...                                                 ...   \n",
       "4347  [{'index': 0, 'from': 0, 'to': 1, 'term': 'NA'...   \n",
       "4348  [{'index': 0, 'from': 0, 'to': 1, 'term': 'NA'...   \n",
       "4349  [{'index': 0, 'from': 0, 'to': 1, 'term': 'NA'...   \n",
       "4350    [{'index': 0, 'from': 1, 'to': 2, 'term': 'I'}]   \n",
       "4351   [{'index': 0, 'from': 0, 'to': 1, 'term': 'NA'}]   \n",
       "\n",
       "                                               opinions  \n",
       "0      [{'index': 0, 'from': 0, 'to': 1, 'term': 'NA'}]  \n",
       "1     [{'index': 0, 'from': 4, 'to': 5, 'term': 'all'}]  \n",
       "2     [{'index': 0, 'from': 4, 'to': 6, 'term': 'les...  \n",
       "3      [{'index': 0, 'from': 0, 'to': 1, 'term': 'NA'}]  \n",
       "4      [{'index': 0, 'from': 0, 'to': 1, 'term': 'NA'}]  \n",
       "...                                                 ...  \n",
       "4347  [{'index': 0, 'from': 17, 'to': 18, 'term': 'o...  \n",
       "4348  [{'index': 0, 'from': 2, 'to': 3, 'term': 'off...  \n",
       "4349  [{'index': 0, 'from': 4, 'to': 8, 'term': 'at ...  \n",
       "4350  [{'index': 0, 'from': 2, 'to': 7, 'term': 'wil...  \n",
       "4351  [{'index': 0, 'from': 1, 'to': 2, 'term': 'Bes...  \n",
       "\n",
       "[4352 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datas = ['darmstadt_unis','mpqa', 'opener_en']\n",
    "\n",
    "df1 = [pd.read_json(f\"../../final_data/{i}/train_convert.json\") for i in datas]\n",
    "df = pd.concat(df1)\n",
    "df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_json('ddx.json')\n",
    "df2 = pd.read_json('ddx1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>raw_words</th>\n",
       "      <th>words</th>\n",
       "      <th>aspects</th>\n",
       "      <th>holder</th>\n",
       "      <th>opinions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [sent_id, raw_words, words, aspects, holder, opinions]\n",
       "Index: []"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[df1[\"opinions\"] == '[]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(r'ddxx2.json', orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os, json\n",
    "\n",
    "NULL_TOKEN = 'NA'\n",
    "START_WORD = 'NA '\n",
    "NULL_INDEX = 0\n",
    "\n",
    "def char2word_offset(sent, start_end_str):\n",
    "    start, end = [int(i) for i in start_end_str.split(':')]\n",
    "    start, end = start+len(START_WORD), end+len(START_WORD)\n",
    "    word_start, word_end = None, None\n",
    "    space_count = 0\n",
    "    for i in range(len(sent)):\n",
    "        if sent[i]==' ': space_count += 1\n",
    "        if i>=start and word_start is None: word_start = space_count\n",
    "        if i>=end and word_start is not None: word_end = space_count; break\n",
    "    if word_end is None and word_start is not None: word_end = space_count+1\n",
    "    assert (type(word_start) == type(word_end))\n",
    "    if word_start is None: word_start, word_end = NULL_INDEX, NULL_INDEX+1\n",
    "    return int(word_start), int(word_end)\n",
    "\n",
    "def format_convert(original_data, file, threshold=0):\n",
    "    final_data = []\n",
    "    blank_cnt = 0\n",
    "    if 't1' in file: print(f'{threshold} limit for null opinions')\n",
    "    threshold *= len(original_data)\n",
    "\n",
    "    for row in tqdm(original_data):\n",
    "        data = {}\n",
    "        if 't1' in file:\n",
    "            if blank_cnt <= threshold and len(row['opinions'])==0: blank_cnt += 1\n",
    "            elif len(row['opinions'])==0: continue\n",
    "\n",
    "        row['text'] = START_WORD + row['text']\n",
    "        data['sent_id'] = row['sent_id']\n",
    "        data['raw_words'] = row['text']\n",
    "        data['words'] = data['raw_words'].split()\n",
    "        aspects, holders, opinions = [], [], []\n",
    "\n",
    "        for cnt, original_opinion in enumerate(row['opinions']):\n",
    "            aspect, holder, opinion = {}, {}, {}\n",
    "            aspect['index'], holder['index'], opinion['index'] = cnt, cnt, cnt\n",
    "\n",
    "            ############################################# Aspect #############################################\n",
    "            try:aspect['from'], aspect['to'] = char2word_offset(data['raw_words'], original_opinion['Target'][1][0])\n",
    "            except: aspect['from'], aspect['to'] = NULL_INDEX, NULL_INDEX+1\n",
    "            if aspect['from'] == aspect['to']-1 == NULL_INDEX:\n",
    "                aspect['term'] = NULL_TOKEN\n",
    "            else:\n",
    "                aspect['term'] = original_opinion['Target'][0][0]\n",
    "\n",
    "            try: aspect['Polarity'] = str(original_opinion['Polarity'])\n",
    "            except: aspect['Polarity'] = NULL_TOKEN; print(original_opinion)\n",
    "            try: aspect['Intensity'] = str(original_opinion['Intensity'])\n",
    "            except: aspect['Intensity'] = NULL_TOKEN; print(original_opinion)\n",
    "\n",
    "            ############################################# Holder #############################################\n",
    "            try:holder['from'], holder['to'] = char2word_offset(data['raw_words'], original_opinion['Source'][1][0])\n",
    "            except: holder['from'], holder['to'] = NULL_INDEX, NULL_INDEX+1\n",
    "            if holder['from'] == holder['to']-1 == NULL_INDEX:\n",
    "                holder['term'] = NULL_TOKEN\n",
    "            else:\n",
    "                holder['term']  = original_opinion['Source'][0][0]\n",
    "\n",
    "            ############################################# Opinion #############################################\n",
    "            try:opinion['from'], opinion['to'] = char2word_offset(data['raw_words'], original_opinion['Polar_expression'][1][0])\n",
    "            except: opinion['from'], opinion['to'] = NULL_INDEX, NULL_INDEX+1\n",
    "            if opinion['from'] == opinion['to']-1 == NULL_INDEX:\n",
    "                opinion['term'] = NULL_TOKEN\n",
    "            else:\n",
    "                opinion['term'] = original_opinion['Polar_expression'][0][0]\n",
    "\n",
    "            aspects.append(aspect)\n",
    "            holders.append(holder)\n",
    "            opinions.append(opinion)\n",
    "\n",
    "        if len(aspects) == 0:\n",
    "            tmp = {}; tmp['index'] = 0; tmp['from']=NULL_INDEX; tmp['to']=NULL_INDEX+1\n",
    "            for k in 'term Polarity Intensity'.split(): tmp[k]=NULL_TOKEN\n",
    "            aspects = [tmp]\n",
    "        if len(holders) == 0:\n",
    "            tmp = {}; tmp['index'] = 0; tmp['from']=NULL_INDEX; tmp['to']=NULL_INDEX+1\n",
    "            for k in 'term'.split(): tmp[k]=NULL_TOKEN\n",
    "            holders = [tmp]\n",
    "        if len(opinions) == 0:\n",
    "            tmp = {}; tmp['index'] = 0; tmp['from']=NULL_INDEX; tmp['to']=NULL_INDEX+1\n",
    "            for k in 'term'.split(): tmp[k]=NULL_TOKEN\n",
    "            opinions = [tmp]\n",
    "\n",
    "        data['aspects'] = aspects\n",
    "        data['holder'] = holders\n",
    "        data['opinions'] = opinions\n",
    "        final_data.append(data)\n",
    "\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 232/232 [00:00<00:00, 77672.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../final_data/darmstadt_unis/dev_convert.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 318/318 [00:00<00:00, 105965.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../final_data/darmstadt_unis/test_convert.json\n",
      "\n",
      "225.3 limit for null opinions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2253/2253 [00:00<00:00, 132511.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../final_data/darmstadt_unis/train_convert.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1997/1997 [00:00<00:00, 86808.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../final_data/mpqa/dev_convert.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2055/2055 [00:00<00:00, 89336.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../final_data/mpqa/test_convert.json\n",
      "\n",
      "564.3000000000001 limit for null opinions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5643/5643 [00:00<00:00, 115129.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../final_data/mpqa/train_convert.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 167/167 [00:00<00:00, 33400.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../final_data/multibooked_ca/dev_convert.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 335/335 [00:00<00:00, 41815.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../final_data/multibooked_ca/test_convert.json\n",
      "\n",
      "117.4 limit for null opinions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1174/1174 [00:00<00:00, 40483.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../final_data/multibooked_ca/train_convert.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:00<00:00, 37973.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../final_data/multibooked_eu/dev_convert.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 305/305 [00:00<00:00, 43549.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../final_data/multibooked_eu/test_convert.json\n",
      "\n",
      "106.30000000000001 limit for null opinions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1063/1063 [00:00<00:00, 46206.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../final_data/multibooked_eu/train_convert.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1531/1531 [00:00<00:00, 63774.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../final_data/norec/dev_convert.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1272/1272 [00:00<00:00, 57811.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../final_data/norec/test_convert.json\n",
      "\n",
      "863.4000000000001 limit for null opinions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8634/8634 [00:00<00:00, 46442.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../final_data/norec/train_convert.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 249/249 [00:00<00:00, 35570.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../final_data/opener_en/dev_convert.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 499/499 [00:00<00:00, 35640.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../final_data/opener_en/test_convert.json\n",
      "\n",
      "174.4 limit for null opinions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1744/1744 [00:00<00:00, 41515.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../final_data/opener_en/train_convert.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 206/206 [00:00<00:00, 25751.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../final_data/opener_es/dev_convert.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 410/410 [00:00<00:00, 21573.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../final_data/opener_es/test_convert.json\n",
      "\n",
      "143.8 limit for null opinions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1438/1438 [00:00<00:00, 27646.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../final_data/opener_es/train_convert.json\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "null_dict = {\n",
    "    'mpqa': 0.1,\n",
    "    'darmstadt_unis': 0.1,\n",
    "    'norec': 0.1,\n",
    "    'opener_en': 0.1,\n",
    "    'multibooked_eu': 0.1,\n",
    "    'multibooked_ca': 0.1,\n",
    "    'opener_es': 0.1,\n",
    "    \"eng_combined\": 0.1\n",
    "}\n",
    "\n",
    "for folder in os.listdir('../../final_data'):\n",
    "    for file in os.listdir(f'../../final_data/{folder}'):\n",
    "        if '1.' not in file: continue\n",
    "        with open(f'../../final_data/{folder}/{file}', encoding=\"utf8\") as f: data = json.load(f)\n",
    "\n",
    "        data = format_convert(data, file, null_dict[folder])\n",
    "        if 't1' in file: dest = 'train_convert.json'\n",
    "        elif 'd1' in file: dest = 'dev_convert.json'\n",
    "        elif 'f1' in file: dest = 'test_convert.json'\n",
    "        print(f'../../final_data/{folder}/{dest}')\n",
    "        # with open(f'../../final_data/{folder}/{dest}', 'w') as f:\n",
    "        #     json.dump(data, f)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
